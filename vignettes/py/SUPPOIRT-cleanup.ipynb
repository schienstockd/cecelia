{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822562ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import working directory to check functions\n",
    "os.chdir('/Users/Dominik/R-workspace/cecelia/inst')\n",
    "\n",
    "# MacOS\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "# config\n",
    "import py.config_utils as cfg\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Volumes/USER_data/Dominik/CECELIA_BACKUP/CV5iNI/ANALYSIS/'\n",
    "zero_dir = os.path.join(base_dir, '0/HYmMxh/')\n",
    "im_path = os.path.join(zero_dir, 'ccidImage.ome.zarr')\n",
    "version_num = 1\n",
    "task_dir = os.path.join(base_dir, str(version_num), 'HYmMxh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py.zarr_utils as zarr_utils\n",
    "\n",
    "im, _ = zarr_utils.open_as_zarr(im_path)\n",
    "im = im[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f93a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py.ome_xml_utils as ome_xml_utils\n",
    "from py.dim_utils import DimUtils\n",
    "\n",
    "# get OME-XML\n",
    "omexml = ome_xml_utils.parse_meta(im_path)\n",
    "\n",
    "# create dim utils for image\n",
    "dim_utils = DimUtils(omexml, use_channel_axis = True)\n",
    "dim_utils.calc_image_dimensions(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcbaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_one = None\n",
    "img_one_tensor = torch.zeros(61, dim_utils.dim_val('X'), dim_utils.dim_val('Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e516c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memmap_image = tifffile.memmap(\n",
    "    f\"{self.parent.save_header}/{metadata}/denoised.tif\",\n",
    "    shape = self.parent.img_shape,\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    (t, _, _) = self.parent.img_shape\n",
    "    self.parent.model.eval()\n",
    "\n",
    "    # for ti in range(t):\n",
    "    for ti in range(\n",
    "        self.parent.actual_start_idx - 1, self.parent.actual_end_idx\n",
    "    ):\n",
    "        if self._isRunning == False:\n",
    "            break\n",
    "        self._ti = ti\n",
    "\n",
    "        counter += 1\n",
    "        if (time.time() - start_time) > 1:\n",
    "            fps = counter / (time.time() - start_time)\n",
    "            self.parent.Label_fps.setText(f\"fps : {fps:2.2f}\")\n",
    "            counter = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "        start_idx = max(ti - 30, 0)\n",
    "        end_idx = min(ti + 31, t)\n",
    "        # print(ti)\n",
    "\n",
    "        pad_front = max(30 - ti, 0)\n",
    "        pad_end = max(31 - (t - ti), 0)\n",
    "        # print(pad_front, pad_end)\n",
    "\n",
    "        img_one = tifffile.imread(\n",
    "            self.parent.img_path, key=range(start_idx, end_idx, 1)\n",
    "        )\n",
    "        img_one_tensor[pad_front : 61 - pad_end, :, :] = torch.from_numpy(\n",
    "            img_one.astype(np.float32)\n",
    "        ).type(torch.FloatTensor)\n",
    "        if pad_front >= 1:\n",
    "            img_one_tensor[0:pad_front, :, :] = img_one_tensor[\n",
    "                pad_front\n",
    "            ].repeat(pad_front, 1, 1)\n",
    "        if pad_end >= 1:\n",
    "            img_one_tensor[61 - pad_end :, :, :] = img_one_tensor[\n",
    "                61 - pad_end - 1\n",
    "            ].repeat(pad_end, 1, 1)\n",
    "\n",
    "        if ti == self.parent.actual_start_idx - 1:\n",
    "            mean_one = torch.mean(img_one_tensor).item()\n",
    "            std_one = torch.std(img_one_tensor).item()\n",
    "\n",
    "        w = 128 if self.parent.img_w > 128 else self.parent.img_w\n",
    "        h = 128 if self.parent.img_h > 128 else self.parent.img_h\n",
    "\n",
    "        testset = DatasetSupport_test_stitch(\n",
    "            img_one_tensor.clone().detach(),\n",
    "            patch_size=[61, w, h],\n",
    "            patch_interval=[1, w // 2, h // 2],\n",
    "            mean_image=mean_one,\n",
    "            std_image=std_one,\n",
    "        )\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=4)\n",
    "        self.test_dataloader = testloader\n",
    "\n",
    "        denoised_frame = np.zeros(\n",
    "            (1, *self.test_dataloader.dataset.noisy_image.shape[1:]),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        for _, (noisy_image, _, single_coordinate) in enumerate(\n",
    "            self.test_dataloader\n",
    "        ):\n",
    "            if self.parent.cuda:\n",
    "                noisy_image = noisy_image.cuda()  # [b, z, y, x]\n",
    "\n",
    "            noisy_image_denoised = self.parent.model(noisy_image)\n",
    "\n",
    "            for bi in range(noisy_image.size(0)):\n",
    "                stack_start_w = int(single_coordinate[\"stack_start_w\"][bi])\n",
    "                stack_end_w = int(single_coordinate[\"stack_end_w\"][bi])\n",
    "                patch_start_w = int(single_coordinate[\"patch_start_w\"][bi])\n",
    "                patch_end_w = int(single_coordinate[\"patch_end_w\"][bi])\n",
    "\n",
    "                stack_start_h = int(single_coordinate[\"stack_start_h\"][bi])\n",
    "                stack_end_h = int(single_coordinate[\"stack_end_h\"][bi])\n",
    "                patch_start_h = int(single_coordinate[\"patch_start_h\"][bi])\n",
    "                patch_end_h = int(single_coordinate[\"patch_end_h\"][bi])\n",
    "\n",
    "\n",
    "                denoised_frame[\n",
    "                    0,  # stack_start_s,\n",
    "                    stack_start_h:stack_end_h,\n",
    "                    stack_start_w:stack_end_w,\n",
    "                ] = (\n",
    "                    noisy_image_denoised[bi]\n",
    "                    .squeeze()[\n",
    "                        patch_start_h:patch_end_h, patch_start_w:patch_end_w\n",
    "                    ]\n",
    "                    .cpu()\n",
    "                )\n",
    "\n",
    "        denoised_frame = denoised_frame * std_one + mean_one\n",
    "\n",
    "        disp_raw = img_one_tensor[30].detach().numpy()\n",
    "        disp_denoised = denoised_frame[0]\n",
    "\n",
    "        if ti == self.parent.actual_start_idx - 1:\n",
    "            vmin = np.min(disp_raw)\n",
    "            vmax = np.percentile(disp_raw, q=99) # np.max(disp_raw)\n",
    "\n",
    "        self.parent.disp_raw = np.clip(\n",
    "            1.2 * (disp_raw - vmin) / (vmax - vmin), 0, 1\n",
    "        )\n",
    "        self.parent.disp_denoised = np.clip(\n",
    "            1.2 * (disp_denoised - vmin) / (vmax - vmin), 0, 1\n",
    "        )\n",
    "\n",
    "        self.signal_update_img.emit(1)\n",
    "        self.progressbar_update.emit(1)\n",
    "\n",
    "        memmap_image[ti, :, :] = denoised_frame\n",
    "\n",
    "        # if ti == self.parent.actual_start_idx - 1:\n",
    "            # tifffile.imwrite(\n",
    "            #     f\"{self.parent.save_header}/{metadata}/denoised.tif\",\n",
    "            #     denoised_frame,\n",
    "            #     dtype=\"float32\",\n",
    "            #     metadata={'axes': 'TYX', 'imagej_metadata': self.parent.imagej_metadata, }\n",
    "            # )\n",
    "        # else:\n",
    "            # tifffile.imwrite(\n",
    "            #     f\"{self.parent.save_header}/{metadata}/denoised.tif\",\n",
    "            #     denoised_frame,\n",
    "            #     append=True,\n",
    "            #     dtype=\"float32\",\n",
    "            #     metadata={'axes': 'TYX', 'imagej_metadata': self.parent.imagej_metadata}\n",
    "            # )\n",
    "\n",
    "    memmap_image.flush()\n",
    "    del memmap_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
